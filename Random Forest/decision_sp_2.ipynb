{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c74b141",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import math\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.impute import SimpleImputer, KNNImputer\n",
    "from sklearn.preprocessing import FunctionTransformer, RobustScaler, StandardScaler, OneHotEncoder, PowerTransformer\n",
    "from imblearn.pipeline import Pipeline as ImbPipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV, StratifiedKFold, RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report, roc_auc_score, confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from scipy.stats import chi2_contingency\n",
    "import matplotlib.ticker as mticker \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6f703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df = pd.read_csv('customer_data.csv')\n",
    "payment_df = pd.read_csv('payment_data.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e834383",
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae25463d",
   "metadata": {},
   "outputs": [],
   "source": [
    "payment_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cace64d",
   "metadata": {},
   "source": [
    "### payment_data.csv:\n",
    "Lịch sử thanh toán thẻ của khách hàng.\n",
    "\n",
    "- **id**: mã khách hàng\n",
    "- **OVD_t1**: số lần quá hạn loại 1\n",
    "- **OVD_t2**: số lần quá hạn loại 2\n",
    "- **OVD_t3**: số lần quá hạn loại 3\n",
    "- **OVD_sum**: tổng số ngày quá hạn\n",
    "- **pay_normal**: số lần thanh toán bình thường\n",
    "- **prod_code**: mã sản phẩm tín dụng\n",
    "- **prod_limit**: hạn mức tín dụng của sản phẩm\n",
    "- **update_date**: ngày cập nhật tài khoản\n",
    "- **new_balance**: số dư hiện tại của sản phẩm\n",
    "- **highest_balance**: số dư cao nhất trong lịch sử\n",
    "- **report_date**: ngày thanh toán gần nhất\n",
    "\n",
    "### customer_data.csv:\n",
    "Dữ liệu nhân khẩu học và các thuộc tính danh mục của khách hàng đã được mã hóa.\n",
    "\n",
    "- `fea_1`\n",
    "- `fea_3`\n",
    "- `fea_5`\n",
    "- `fea_6`\n",
    "- `fea_7`\n",
    "- `fea_9`\n",
    "- **label** là 1: khách hàng có rủi ro tín dụng cao\n",
    "- **label** là 0: khách hàng có rủi ro tín dụng thấp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d768163e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full = pd.merge(customer_df, payment_df, on='id',how=\"inner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43ddbe81",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c318ba50",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Chuyển cột ngày tháng năm sang datetime\n",
    "date_columns = ['update_date', 'report_date']\n",
    "for col in date_columns:\n",
    "    df_full[col] = pd.to_datetime(df_full[col], format='%d/%m/%Y', errors='coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2f4dfcf",
   "metadata": {},
   "source": [
    "## 1. Quick glance at data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a0ec3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.describe().T.round()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f6697c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ccecf6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def missing_values_table(df):\n",
    "        mis_val = df.isnull().sum()\n",
    "        mis_val_percent = 100 * df.isnull().sum() / len(df)\n",
    "        mz_table = pd.concat([mis_val, mis_val_percent], axis=1)\n",
    "        mz_table = mz_table.rename(columns = {0 : 'Missing Values', 1 : '% of Total Values'})\n",
    "        mz_table = mz_table[mz_table.iloc[:,1] != 0].sort_values('% of Total Values', ascending=False).round(1)\n",
    "        return mz_table\n",
    "missing_values_table(df_full)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c22e74f",
   "metadata": {},
   "source": [
    "## 2. EDA cơ bản + xử lý dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36873bad",
   "metadata": {},
   "source": [
    "### Xem phân phối tổng quát"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2251cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định lại các cột số và cột phân loại\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_10','fea_8','fea_11',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "categorical_cols = [\n",
    "    'label', 'fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7',  'fea_9', \n",
    "    'prod_code'\n",
    "]\n",
    "\n",
    "# Vẽ KDE plot cho các cột số (3 đồ thị trên 1 hàng)\n",
    "print(\"Các cột numeric\")\n",
    "n_numerical = len(numerical_cols)\n",
    "n_rows_numerical = math.ceil(n_numerical / 3)\n",
    "fig_numerical, axes_numerical = plt.subplots(n_rows_numerical, 3, figsize=(18, n_rows_numerical * 5))\n",
    "axes_numerical = axes_numerical.flatten()\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    sns.kdeplot(data=df_full, x=col, fill=True, ax=axes_numerical[i])\n",
    "    axes_numerical[i].set_title(f'Phân phối của cột: {col}')\n",
    "    axes_numerical[i].set_xlabel(col)\n",
    "    axes_numerical[i].set_ylabel('Mật độ')\n",
    "\n",
    "# Ẩn các subplot không sử dụng\n",
    "for j in range(i + 1, len(axes_numerical)):\n",
    "    fig_numerical.delaxes(axes_numerical[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Vẽ biểu đồ cột cho các cột phân loại (3 đồ thị trên 1 hàng)\n",
    "print(\"Các cột category\")\n",
    "n_categorical = len(categorical_cols)\n",
    "n_rows_categorical = math.ceil(n_categorical / 3)\n",
    "fig_categorical, axes_categorical = plt.subplots(n_rows_categorical, 3, figsize=(18, n_rows_categorical * 5))\n",
    "axes_categorical = axes_categorical.flatten()\n",
    "\n",
    "for i, col in enumerate(categorical_cols):\n",
    "    sns.countplot(data=df_full, x=col, ax=axes_categorical[i])\n",
    "    axes_categorical[i].set_title(f'Phân phối của cột: {col}')\n",
    "    axes_categorical[i].set_xlabel(col)\n",
    "    axes_categorical[i].set_ylabel('Số lượng')\n",
    "\n",
    "    # Sửa lỗi ở đây: Sử dụng set_xticklabels để xoay và căn chỉnh nhãn\n",
    "    axes_categorical[i].set_xticklabels(axes_categorical[i].get_xticklabels(), rotation=45, ha='right')\n",
    "\n",
    "\n",
    "# Ẩn các subplot không sử dụng\n",
    "for j in range(i + 1, len(axes_categorical)):\n",
    "    fig_categorical.delaxes(axes_categorical[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af1a5249",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các cột số (bao gồm fea_8 và fea_10)\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_10', 'fea_8',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Chọn chỉ các cột số từ DataFrame\n",
    "df_numerical = df_full[numerical_cols]\n",
    "\n",
    "# Tính ma trận tương quan\n",
    "correlation_matrix = df_numerical.corr()\n",
    "\n",
    "# Vẽ heatmap của ma trận tương quan\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap ma trận tương quan')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abd87250",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xem xem có id nào bị gán nhãn là cả 0 và 1 không\n",
    "df_full.groupby('id')[\"label\"].nunique().pipe(lambda x: x[x > 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e84448fd",
   "metadata": {},
   "source": [
    "### Tìm hiểu những cột NULL + đề xuất phương án xử lý"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "438c450f",
   "metadata": {},
   "source": [
    "### ***C. Tìm hiểu vấn đề về cột prod_limit***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "821dae36",
   "metadata": {},
   "source": [
    "Tạo biến chỉ báo prod_limit_is_missing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e147cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Check xem nhóm rủi ro cao có tỷ lệ thiếu \"prod_limit\" cao hơn không\n",
    "df_full['prod_limit_is_missing'] = df_full['prod_limit'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c95dc92",
   "metadata": {},
   "source": [
    "#### 1. Phân tích null của cột này"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06988486",
   "metadata": {},
   "source": [
    "a. Giả thuyết: Null có nghĩa là \"sản phẩm không có hạn mức tín dụng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c69e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính tỷ lệ prod_limit bị thiếu cho mỗi prod_code và sắp xếp\n",
    "prod_code_missing_ratio = df_full.groupby('prod_code')['prod_limit'].apply(lambda x: x.isnull().mean()*100).sort_values(ascending=False)\n",
    "\n",
    "print(\"\\nTỷ lệ prod_limit bị thiếu theo từng prod_code (sắp xếp từ cao đến thấp):\")\n",
    "print(prod_code_missing_ratio.head(20)) # In ra 20 dòng đầu để xem\n",
    "\n",
    "# Vẽ biểu đồ cột\n",
    "plt.figure(figsize=(15, 7)) # Điều chỉnh kích thước figure\n",
    "prod_code_missing_ratio.plot(kind='bar')\n",
    "plt.title('Tỷ lệ Prod_limit bị thiếu theo Prod_code')\n",
    "plt.xlabel('Prod_code')\n",
    "plt.ylabel('Tỷ lệ thiếu (%)')\n",
    "plt.xticks(rotation=45, ha='right') # Xoay nhãn trục x để dễ đọc\n",
    "plt.tight_layout() # Điều chỉnh layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51694a2d",
   "metadata": {},
   "source": [
    "-> Tôi thấy một vài sản phẩm (ngoại trừ 22,10) có tỷ lệ null của cột prod_limit là 100%. Tuy nhiên các cột prod_code = 22, 10 thì lại có tỷ lệ không phải 100%. Chứng tỏ 2 cột này có tồn tại null -> Chứng tỏ null không đại diện cho \"sản phẩm không có khái niệm giới hạn định mức\" (bởi 22,10 vẫn bị giới hạn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b59ee15",
   "metadata": {},
   "source": [
    "Tôi lại nghĩ đến giả thiết khác xảy ra là: với những giá trị null, nó ám chỉ đến việc sản phẩm này (tương ứng với người dùng nào đó sử dụng) chưa bị áp hạn mức do chưa vi phạm điều gì đó ?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "642c5624",
   "metadata": {},
   "source": [
    "b. Giả thuyết 2: Ban đầu, sản phẩm người dùng không bị giới hạn tín dụng (tức prod_limit = NULL). Nhưng sau đó, do vi phạm chính sách nào đó (hoặc có thể vì vấn đề nào đó khác) dẫn đến việc người đó bị prod_limit khác null (tức là lúc này người này bị giới hạn tín dụng)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94a5eaa2",
   "metadata": {},
   "source": [
    "Việc vi phạm chính sách dẫn đến prod_limit bị khác null (tức là lúc đó người dùng bị áp đặt hạn mức) có thể liên quan đến biến OVD_t1, OVD_t2, OVD_t3, OVD_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af7135b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\nMô tả các biến OVD và pay_normal khi prod_limit BỊ THIẾU:\")\n",
    "print(df_full[df_full['prod_limit'].isnull()][['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal']].describe())\n",
    "\n",
    "print(\"\\nMô tả các biến OVD và pay_normal khi prod_limit KHÔNG BỊ THIẾU:\")\n",
    "print(df_full[df_full['prod_limit'].notnull()][['OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a6ddd1",
   "metadata": {},
   "source": [
    "##### -> Ở đây ta thấy được rằng: \n",
    "+ các giá trị mean tương ứng của các cột OVD khi prod_limit thiếu đều lớn hơn so với prod_limit không thiếu\n",
    "+ mặt khác, pay_normal (chi trả bình thường) khi prod_limit thiếu thì mean lại có xu hướng ít hơn so với TH không bị thiếu (có thể là khi bị giới hạn tín dụng rồi, họ mới chi trả bthg. Còn đâu lúc ch bị, họ hay cheat)\n",
    "+ Ở phần max cũng đa phần đều lớn hơn hoặc bằng  \n",
    "##### -> Các điều trên đang củng cố giả thuyết của chúng ta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afdb5dc8",
   "metadata": {},
   "source": [
    "##### Ta tập trung vào các prod_code 22 và 10 do chúng có tồn tại những giá trị vừa null vừa 0 null ở cột prod_limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeeadfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_10_and_22 = df_full[(df_full['prod_code'] == 10) | (df_full['prod_code'] == 22)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13411828",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Nhóm theo id và prod_code, sau đó đếm số lượng bản ghi (không null) cho mỗi nhóm trong cột update_date\n",
    "update_date_counts = df_10_and_22.groupby([\"id\",\"prod_code\",\"update_date\"])[\"prod_limit_is_missing\"].value_counts().head(20)\n",
    "\n",
    "print(\"Số lượng bản ghi theo ID và Prod_code và update_date (cho prod_limit_is_missing):\")\n",
    "print(update_date_counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dc4e95f",
   "metadata": {},
   "source": [
    "-> Củng cố thêm giả thuyết của ta rằng: có khoảng thời gian, người dùng bị giối hạn, sau được gỡ, sau lại bị giới hạn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01b358b0",
   "metadata": {},
   "source": [
    "#### Vậy giá trị null ở đây có thể là các TH khả nghi như:\n",
    "Khách hàng không đủ điều kiện để được cấp hạn mức tín dụng rõ ràng (có thể liên quan đến rủi ro của họ).Trong một số trường hợp, hạn mức có thể đã từng được áp dụng rồi lại được gỡ bỏ, cho thấy một quy trình quản lý hạn mức động"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90830291",
   "metadata": {},
   "source": [
    "#### 2. kiểm tra xem cột prod_limit_is_missing mới này có ảnh hưởng đến target không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f11c6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử các thư viện cần thiết (pandas, matplotlib.pyplot, seaborn) đã được import và df_full đã được tạo\n",
    "\n",
    "# Lọc ra nhóm khách hàng có rủi ro thấp (label == 0)\n",
    "low_risk_df = df_full[df_full['label'] == 0]\n",
    "\n",
    "# Lọc ra nhóm khách hàng có rủi ro cao (label == 1)\n",
    "high_risk_df = df_full[df_full['label'] == 1]\n",
    "\n",
    "# Đếm số lượng cho từng trường hợp thiếu/không thiếu prod_limit trong nhóm rủi ro thấp\n",
    "missing_limit_counts_low_risk = low_risk_df['prod_limit'].isnull().value_counts()\n",
    "\n",
    "# Đếm số lượng cho từng trường hợp thiếu/không thiếu prod_limit trong nhóm rủi ro cao\n",
    "missing_limit_counts_high_risk = high_risk_df['prod_limit'].isnull().value_counts()\n",
    "\n",
    "\n",
    "# Tạo figure và các subplots (1 hàng, 2 cột)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9)) # Giữ kích thước figure\n",
    "\n",
    "# Màu sắc tùy chỉnh (ví dụ: sử dụng bảng màu 'viridis' từ seaborn)\n",
    "colors = sns.color_palette('viridis', 2) # Lấy 2 màu từ bảng màu viridis\n",
    "\n",
    "# Nhãn cho biểu đồ tròn\n",
    "pie_labels = ['Không thiếu Prod_limit', 'Thiếu Prod_limit']\n",
    "\n",
    "# Vẽ biểu đồ tròn cho nhóm rủi ro thấp trên subplot đầu tiên\n",
    "axes[0].pie(missing_limit_counts_low_risk,\n",
    "            labels=pie_labels,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            textprops={'fontsize': 11, 'color': 'black', 'weight': 'bold'}) # Điều chỉnh màu và độ đậm của chữ\n",
    "\n",
    "axes[0].set_title('Nhóm rủi ro thấp (Label = 0)', fontsize=14)\n",
    "axes[0].axis('equal') # Đảm bảo biểu đồ tròn là hình tròn\n",
    "\n",
    "# Vẽ biểu đồ tròn cho nhóm rủi ro cao trên subplot thứ hai\n",
    "axes[1].pie(missing_limit_counts_high_risk,\n",
    "            labels=pie_labels,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            textprops={'fontsize': 11, 'color': 'black', 'weight': 'bold'}) # Điều chỉnh màu và độ đậm của chữ\n",
    "\n",
    "axes[1].set_title('Nhóm rủi ro cao (Label = 1)', fontsize=14)\n",
    "axes[1].axis('equal') # Đảm bảo biểu đồ tròn là hình tròn\n",
    "\n",
    "plt.tight_layout() # Điều chỉnh layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f7f1bd",
   "metadata": {},
   "source": [
    "Như tôi dự đoán ở trên nãy, do tôi vẫn nghĩ có thể khả năng cao null ở đây mang nghĩa không bị giới hạn tín dụng, còn khác null mang nghĩa bị giới hạn tín dụng (có thể do người dùng vi phạm chính sách thẻ dẫn đến rủi ro hay là tự đặt giới hạn cho thẻ khi nhận thấy rủi ro,...) thế nên ở đây prod_limit bị thiếu ở nhóm rủi ro thấp có xu hướng cao hơn prod_limit bị thiếu ở nhóm rủi ro cao. Tuy nhiên, như tôi nói, đây vẫn chỉ là giả định của tôi chứ thực tế ra sao chúng ta cần hỏi người cung cấp dữ liệu"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aed13a4",
   "metadata": {},
   "source": [
    "2 biểu đồ tròn trên là khi ta so sánh trong TH: (id,lanbel,prod_code) bị lặp lại, tức là khi thẻ của 1 người nào đó bị xuất hiện prod_limit null nhiều lần (và cả không null cũng xuất hiện nhiều lần với thẻ đó) và trong tất cả TH thì người đó đều bị coi là label 1  \n",
    "VD:\n",
    "Khi biểu điễn bảng:   \n",
    "id - prod_code - update_date - prod_limit - label  \n",
    "1999 - 10 - 3/2 - null - 1      \n",
    "1999 - 10 - 4/5 - null - 1    \n",
    "1999 - 10 - 4/5 - không null - 1     \n",
    "1999 - 10 - 5/5 - null - 1  \n",
    "1999 - 10 - 6/5 - không null - 1  \n",
    "-> Ta thấy vấn đề ở đây là một người bị xét là null quá nhiều lần, trong khi label người đó thì đã bị gán là 1. Vậy nên việc so sánh như trên là có vẻ chưa trung thực lắm (vì chỉ cần người đó bị gán label 1 cái là tất cả prod_limit dù null hay không null của người đó đều có label = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "037fe930",
   "metadata": {},
   "source": [
    "Đề xuất xử lý: tạo 1 dataframe khác loại bỏ trùng ở các cột id, prod_limit_is_missing với mục tiêu: tránh để prod_limit xuất hiện nhiều lần trên cùng một người "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3d33f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_remove_dup_id_prod = df_full.drop_duplicates(subset=[\"id\", \"prod_limit_is_missing\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a30ea1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử các thư viện cần thiết (pandas, matplotlib.pyplot, seaborn) đã được import và df_full đã được tạo\n",
    "\n",
    "# Lọc ra nhóm khách hàng có rủi ro thấp (label == 0)\n",
    "low_risk_df = df_remove_dup_id_prod[df_remove_dup_id_prod['label'] == 0]\n",
    "\n",
    "# Lọc ra nhóm khách hàng có rủi ro cao (label == 1)\n",
    "high_risk_df = df_remove_dup_id_prod[df_remove_dup_id_prod['label'] == 1]\n",
    "\n",
    "# Đếm số lượng cho từng trường hợp thiếu/không thiếu prod_limit trong nhóm rủi ro thấp\n",
    "missing_limit_counts_low_risk = low_risk_df['prod_limit'].isnull().value_counts()\n",
    "\n",
    "# Đếm số lượng cho từng trường hợp thiếu/không thiếu prod_limit trong nhóm rủi ro cao\n",
    "missing_limit_counts_high_risk = high_risk_df['prod_limit'].isnull().value_counts()\n",
    "\n",
    "\n",
    "# Tạo figure và các subplots (1 hàng, 2 cột)\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 9)) # Giữ kích thước figure\n",
    "\n",
    "# Màu sắc tùy chỉnh (ví dụ: sử dụng bảng màu 'viridis' từ seaborn)\n",
    "colors = sns.color_palette('viridis', 2) # Lấy 2 màu từ bảng màu viridis\n",
    "\n",
    "# Nhãn cho biểu đồ tròn\n",
    "pie_labels = ['Không thiếu Prod_limit', 'Thiếu Prod_limit']\n",
    "\n",
    "# Vẽ biểu đồ tròn cho nhóm rủi ro thấp trên subplot đầu tiên\n",
    "axes[0].pie(missing_limit_counts_low_risk,\n",
    "            labels=pie_labels,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            textprops={'fontsize': 11, 'color': 'black', 'weight': 'bold'}) # Điều chỉnh màu và độ đậm của chữ\n",
    "\n",
    "axes[0].set_title('Prod_limit trong nhóm rủi ro thấp (Label = 0)', fontsize=14)\n",
    "axes[0].axis('equal') # Đảm bảo biểu đồ tròn là hình tròn\n",
    "\n",
    "# Vẽ biểu đồ tròn cho nhóm rủi ro cao trên subplot thứ hai\n",
    "axes[1].pie(missing_limit_counts_high_risk,\n",
    "            labels=pie_labels,\n",
    "            autopct='%1.1f%%',\n",
    "            startangle=90,\n",
    "            colors=colors,\n",
    "            wedgeprops={'edgecolor': 'white', 'linewidth': 1.5},\n",
    "            textprops={'fontsize': 11, 'color': 'black', 'weight': 'bold'}) # Điều chỉnh màu và độ đậm của chữ\n",
    "\n",
    "axes[1].set_title('Prod_limit trong nhóm rủi ro cao (Label = 1)', fontsize=14)\n",
    "axes[1].axis('equal') # Đảm bảo biểu đồ tròn là hình tròn\n",
    "\n",
    "plt.tight_layout() # Điều chỉnh layout\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "722d9a08",
   "metadata": {},
   "source": [
    "Ở đây khách quan hơn, tuy vậy chúng ta vẫn thấy prod_limit thiếu ở label = 0 vãn lớn hơn label = 1. Và ở đây tôi nhận định rằng biến prod_limit_is_missing là có ý nghĩa trong việc dự đoán label"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf4c5c1f",
   "metadata": {},
   "source": [
    "Phương án xử lý: \n",
    "+ Giữ prod_limit_is_missing\n",
    "+ Thay các giá trị null của prod_limit bằng giá trị 0 với ý nghĩa: \"khách hàng/sản phẩm đó không có hạn mức tín dụng\" hoặc \"hạn mức không áp dụng\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa2739d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full[\"prod_limit\"] = df_full[\"prod_limit\"].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb4c8c05",
   "metadata": {},
   "source": [
    "### ***A. Phân tích và xử lý cột report_date***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12e20140",
   "metadata": {},
   "source": [
    "#### 1. Phân tích sơ bộ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3538b27f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khoảng thời gian bao phủ:\n",
    "print(f\"Ngày report_date sớm nhất: {df_full['report_date'].min()}\")\n",
    "print(f\"Ngày report_date gần nhất: {df_full['report_date'].max()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b778d48",
   "metadata": {},
   "source": [
    "#### Phán đoán nguyên nhân report_date bị thiếu:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9bb1cc",
   "metadata": {},
   "source": [
    "1. Giả thuyết 1: Do chưa bao giờ giao dịch ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5024db9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_full[df_full['report_date'].isnull()][['OVD_t1', 'OVD_sum', 'pay_normal']].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0aee8ab",
   "metadata": {},
   "source": [
    "-> Sai vì nếu thế OVD_sum ít nhất phải bằng không"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0741d56c",
   "metadata": {},
   "source": [
    "2. Do người thu thập dữ liệu không xác định được thời điểm giao dịch gần nhất ?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73de0cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính tỷ lệ phần trăm giá trị NULL trong cột report_date, nhóm theo id\n",
    "report_date_null_percentage_by_id = df_full.groupby('id')['report_date'].apply(lambda x: x.isnull().mean() * 100)\n",
    "\n",
    "# Sắp xếp kết quả từ lớn nhất đến bé nhất\n",
    "sorted_report_date_null_percentage_by_id = report_date_null_percentage_by_id.sort_values(ascending=False)\n",
    "\n",
    "print(\"Tỷ lệ phần trăm Report Date bị thiếu \\ntheo từng ID (sắp xếp từ cao đến thấp)\\nlấy ra khoảng 20 người:\")\n",
    "print(sorted_report_date_null_percentage_by_id.head(20))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa728525",
   "metadata": {},
   "source": [
    "-> Từ đây ta thấy được là có vài người thì tỷ lệ null của cột đó là 100%, còn một vài người thì 75%, 66%,... Vậy nguyên nhân có thể đúng là do người thu thập có thể không xác định được những giao dịch gần đây hoặc chưa cập nhật những giao dịch gần đây vào trong dữ liệu nên nó mới bị null như vậy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bc93080",
   "metadata": {},
   "source": [
    "#### Kiểm tra kỹ hơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4e759dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tính bảng crosstab với tỷ lệ phần trăm theo hàng\n",
    "crosstab_result = pd.crosstab(df_full['report_date'].isnull(), df_full['label'], normalize='index')\n",
    "\n",
    "# Vẽ biểu đồ cột chồng\n",
    "ax = crosstab_result.plot(kind='bar', stacked=True, figsize=(8, 6), color=['skyblue', 'lightcoral'])\n",
    "\n",
    "plt.title('Tỷ lệ nhóm rủi ro theo trạng thái thiếu Report Date')\n",
    "plt.xlabel('Report Date bị thiếu')\n",
    "plt.ylabel('Tỷ lệ phần trăm')\n",
    "plt.xticks(ticks=[0, 1], labels=['Không thiếu', 'Thiếu'], rotation=0) # Đặt nhãn trục x rõ ràng\n",
    "plt.legend(title='Nhóm rủi ro', labels=['Thấp (0)', 'Cao (1)'])\n",
    "plt.yticks([0, 0.2, 0.4, 0.6, 0.8, 1.0], ['0%', '20%', '40%', '60%', '80%', '100%']) # Định dạng trục y thành phần trăm\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7) # Thêm lưới ngang\n",
    "plt.tight_layout() # Điều chỉnh layout\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bbbf0b6",
   "metadata": {},
   "source": [
    "-> Không có sự khác biệt giữa thiếu/không thiếu report_date đối với label, cho ta thấy được rằng việc thiếu có thể là ngẫu nhiên, không liên quan đến hành vi của khách hàng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86621dab",
   "metadata": {},
   "source": [
    "Tuy nhiên, vì cột này thiếu khá nhiều (13.2%) nên việc tạo biến chỉ báo theo tôi vẫn là nên để mô hình có thể biết được đâu là giá trị ta đã thay null, đâu là giá trị ta chưa thay null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9224c01f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full['report_date_is_missing'] = df_full['report_date'].isnull().astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8605d3c7",
   "metadata": {},
   "source": [
    "#### Phương án xử lý NULL: tách cột này ra thành ngày/ tháng / năm và thay thế null bằng cách dùng KNN Imputer (sau khi chia tập dữ liệu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0dd429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tách cột report_date thành ngày, tháng, năm\n",
    "df_full['report_year'] = df_full['report_date'].dt.year\n",
    "df_full['report_month'] = df_full['report_date'].dt.month\n",
    "df_full['report_day'] = df_full['report_date'].dt.day\n",
    "df_full.drop(\"report_date\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0b1176",
   "metadata": {},
   "source": [
    "### ***B. Tìm hiểu về cột update_date***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c50f96d",
   "metadata": {},
   "source": [
    "Cột này tuy trước đó người thực hiện đã phân tích, nhưng vẫn chưa hiểu rõ ý nghĩa thực sự của cột nên đã xóa đi phần phân tích đó. Vậy nên, người thực hiện xin phép không phân tích"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af7cd693",
   "metadata": {},
   "source": [
    "Ta tập trung xem mấy giá trị null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f95fa0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Tạo biến chỉ báo\n",
    "df_full['update_date_is_missing'] = df_full['update_date'].isnull().astype(int)\n",
    "# Tính bảng chéo tỷ lệ phần trăm theo hàng (Risk Rate)\n",
    "cross_tab_row_pct = pd.crosstab(df_full['update_date_is_missing'], df_full['label'], normalize='index') * 100\n",
    "\n",
    "# Vẽ biểu đồ cột (không chồng)\n",
    "ax1 = cross_tab_row_pct.plot(kind='bar', stacked=False, figsize=(8, 6))\n",
    "plt.title('Tỷ lệ Label theo Trạng thái Thiếu/Đủ của Update Date')\n",
    "plt.xlabel('Update Date Bị Thiếu') # Cập nhật nhãn trục x\n",
    "plt.ylabel('Tỷ lệ Phần trăm (%)')\n",
    "plt.xticks(rotation=0)\n",
    "plt.legend(title='Label')\n",
    "plt.tight_layout()\n",
    "# Đổi nhãn trục x\n",
    "ax1.set_xticklabels(['Không Thiếu', 'Thiếu'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f979799f",
   "metadata": {},
   "source": [
    "-> Chưa đủ để thấy sự khác biệt, mặt khác dữ liệu thiếu là ít (21 dữ liệu) nên ta quyết định bỏ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc5487fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.dropna(subset=[\"update_date\"],inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e186c662",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop([\"update_date_is_missing\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "231d7c96",
   "metadata": {},
   "source": [
    "-> Tiếp tục chia cột này ra thành 3 cột day/month/year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44549c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử cột 'update_date' đã là datetime\n",
    "\n",
    "# Tách cột update_date thành ngày, tháng, năm\n",
    "df_full['update_year'] = df_full['update_date'].dt.year\n",
    "df_full['update_month'] = df_full['update_date'].dt.month\n",
    "df_full['update_day'] = df_full['update_date'].dt.day\n",
    "\n",
    "# Xóa cột update_date gốc\n",
    "df_full.drop(\"update_date\", axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2384f6e8",
   "metadata": {},
   "source": [
    "### ***D. Xử lý null của cột highest_balance*** (Xử lý sau baseline)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a45b3b55",
   "metadata": {},
   "source": [
    "-> Thay thế null của cột này bằng trung bình highest_balance tương ứng của mỗi người"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35a1f6c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lấy ra các highest_balance mỗi người\n",
    "df_subset_highest_balance = df_full[[\"id\",\"highest_balance\"]].drop_duplicates()\n",
    "highest_balance_mean_person = df_subset_highest_balance.groupby('id')['highest_balance'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "517a7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "highest_balance_mean_person"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd4dd6bd",
   "metadata": {},
   "source": [
    "### ***E. Xử lý null của cột fea_2***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac902bc7",
   "metadata": {},
   "source": [
    "Do phân phối của fea_2 là phân phối gần chuẩn, mặt khác giá trị của fea_2 chỉ có giá trị nguyên   \n",
    "-> ta sẽ thay giá trị cột fea_2 bằng median"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74be518b",
   "metadata": {},
   "source": [
    "### **Tóm lại ta có các phương án các cột chứa null như sau**:\n",
    "1. prod_limit: thay null = 0, tạo 1 biến mới có tên prod_limit_is_missing\n",
    "2. report_date: tách cột này thành 3 cột day/month/year, ta sẽ thay null = thuật toán KNN sau khi chia tập dữ liệu\n",
    "3. fea_2: thay null = median của cột đó sau khi chia tập dữ liệu\n",
    "4. update_date: loại bỏ những dòng null, chia cột đó thành 3 cột day/month/year\n",
    "5. highest_balance: thay bằng giá trị trung bình của highest_balance tương ứng với từng id (group by id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a0294d4",
   "metadata": {},
   "source": [
    "## Tiếp tục thực hiên EDA các biến khác"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a49f1fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các cột số (bao gồm fea_8 và fea_10)\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_10', 'fea_8',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_t3', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Chọn chỉ các cột số từ DataFrame\n",
    "df_numerical = df_full[numerical_cols]\n",
    "\n",
    "# Tính ma trận tương quan\n",
    "correlation_matrix = df_numerical.corr()\n",
    "\n",
    "# Vẽ heatmap của ma trận tương quan\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap ma trận tương quan')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77bb0c15",
   "metadata": {},
   "source": [
    "### Quyết định xử lý đa cộng tuyến giữa OVD_t3 và OVD_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "691e2b25",
   "metadata": {},
   "source": [
    "-> Tồn tại đa cộng tuyến cao giữa OVD_t3 và OVD_sum, có khả năng cao 1 trong 2 biến này là thừa. Phương án xử lý khi đa cộng tuyến cao như vậy của tôi sẽ là bỏ 1 trong 2 biến"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71b314ad",
   "metadata": {},
   "source": [
    "Quyết định bỏ biến OVD_t3 vì OVD_sum tổng quát hơn:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e55b2609",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full.drop(\"OVD_t3\",axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5fb721",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các cột số (bao gồm fea_8 và fea_10)\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_10', 'fea_8',\n",
    "    'OVD_t1', 'OVD_t2',  'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Chọn chỉ các cột số từ DataFrame\n",
    "df_numerical = df_full[numerical_cols]\n",
    "\n",
    "# Tính ma trận tương quan\n",
    "correlation_matrix = df_numerical.corr()\n",
    "\n",
    "# Vẽ heatmap của ma trận tương quan\n",
    "plt.figure(figsize=(12, 10))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', fmt=\".2f\")\n",
    "plt.title('Heatmap ma trận tương quan')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35896225",
   "metadata": {},
   "source": [
    "### Quyết định giữ lại biến new_balance và highest_balance (ko xử lý đa cộng tuyến)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1113e72f",
   "metadata": {},
   "source": [
    "Lý do:\n",
    "+ new_balance: Phản ánh tình hình tài chính hiện tại của khách hàng tại thời điểm update_date (hoặc report_date gì đó). Đây là thông tin rất quan trọng và cập nhật.\n",
    "+ highest_balance: Phản ánh mức số dư cao nhất trong lịch sử (tính đến update_date đó hoặc một thời điểm trước đó). Điều này có thể cho biết:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40437853",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định các cột số và thêm cột label vào danh sách\n",
    "numerical_cols_with_label = [\n",
    "    'label', # Thêm label vào danh sách\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_10', 'fea_8',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Chọn chỉ các cột này từ DataFrame\n",
    "df_subset = df_full[numerical_cols_with_label]\n",
    "\n",
    "# Tính ma trận tương quan cho tập con này\n",
    "correlation_matrix_subset = df_subset.corr()\n",
    "\n",
    "# Lấy riêng dòng tương quan với label và sắp xếp\n",
    "label_correlations = correlation_matrix_subset['label'].sort_values(ascending=False)\n",
    "\n",
    "# Loại bỏ chính label khỏi kết quả\n",
    "label_correlations = label_correlations.drop('label')\n",
    "\n",
    "# Vẽ biểu đồ cột cho các hệ số tương quan\n",
    "plt.figure(figsize=(10, 6))\n",
    "label_correlations.plot(kind='bar', color='skyblue')\n",
    "plt.title('Mối quan hệ giữa Label và các biến số')\n",
    "plt.xlabel('Biến số')\n",
    "plt.ylabel('Hệ số tương quan')\n",
    "plt.axhline(y=0, color='black', linestyle='--')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4685d0eb",
   "metadata": {},
   "source": [
    "-> Ít có mối quan hệ tuyến tính, không phù hợp khi sử dụng các mô hình tuyến tính như logistic regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd03550d",
   "metadata": {},
   "source": [
    "## Triển khai mô hình baseline: Logistic Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf69db99",
   "metadata": {},
   "source": [
    "1. Chia tập dữ liệu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6030918",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_full.drop(\"label\", axis=1)\n",
    "y = df_full[\"label\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d567be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42,stratify=y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3ba3317",
   "metadata": {},
   "source": [
    "2. Điền null"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "262d8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Thay null cột fea_2 bằng median do phân phối dạng chuẩn\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='median')\n",
    "\n",
    "imputer.fit(X_train[['fea_2']])\n",
    "\n",
    "X_train['fea_2'] = imputer.transform(X_train[['fea_2']])\n",
    "X_test['fea_2'] = imputer.transform(X_test[['fea_2']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15168bd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xử lý null tại cột highest_balance\n",
    "X_train['highest_balance_mean_by_id'] = X_train.groupby('id')['highest_balance'].transform('mean')\n",
    "\n",
    "# Sử dụng .fillna() với cột trung bình theo id\n",
    "X_train['highest_balance'] = X_train['highest_balance'].fillna(X_train['highest_balance_mean_by_id'])\n",
    "\n",
    "# Bỏ cột trung bình tạm thời\n",
    "X_train = X_train.drop(columns=['highest_balance_mean_by_id'])\n",
    "\n",
    "mean_highest_balance_by_id_train = X_train.groupby('id')['highest_balance'].mean()\n",
    "\n",
    "X_test['highest_balance_mean_by_id'] = X_test['id'].map(mean_highest_balance_by_id_train)\n",
    "\n",
    "# Điền giá trị thiếu trong highest_balance của X_test\n",
    "# Sử dụng .fillna() với cột trung bình theo id từ tập train\n",
    "# Cần một chiến lược dự phòng nếu một id trong X_test không có trong tập train\n",
    "# Ví dụ: điền bằng trung bình tổng thể của highest_balance từ X_train\n",
    "overall_mean_highest_balance_train = X_train['highest_balance'].mean()\n",
    "X_test['highest_balance'] = X_test['highest_balance'].fillna(X_test['highest_balance_mean_by_id']).fillna(overall_mean_highest_balance_train)\n",
    "\n",
    "# Bỏ cột trung bình tạm thời\n",
    "X_test = X_test.drop(columns=['highest_balance_mean_by_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fab2acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Xác định các cột số sẽ được sử dụng cho KNN imputation\n",
    "# Bao gồm các cột cần điền và các cột số khác có thể giúp tìm hàng xóm\n",
    "numerical_features_for_knn = [\n",
    "    \"id\",\"prod_code\",\n",
    "    'report_day', 'report_month', 'report_year',\n",
    "    'update_day', 'update_month', 'update_year', # Các cột ngày tháng đã tách từ update_date\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Chọn chỉ các cột số này từ X_train và X_test\n",
    "X_train_numerical = X_train[numerical_features_for_knn]\n",
    "X_test_numerical = X_test[numerical_features_for_knn]\n",
    "\n",
    "\n",
    "# Khởi tạo KNNImputer\n",
    "imputer = KNNImputer(n_neighbors=5) # Chọn số hàng xóm, bạn có thể điều chỉnh giá trị này\n",
    "\n",
    "# Fit imputer CHỈ trên X_train_numerical và transform X_train_numerical\n",
    "X_train_imputed = imputer.fit_transform(X_train_numerical)\n",
    "\n",
    "# Transform X_test_numerical (KHÔNG FIT LẠI)\n",
    "X_test_imputed = imputer.transform(X_test_numerical)\n",
    "\n",
    "# Kết quả từ imputer là numpy array, cần gán lại vào DataFrame và giữ tên cột\n",
    "X_train[numerical_features_for_knn] = X_train_imputed\n",
    "X_test[numerical_features_for_knn] = X_test_imputed\n",
    "\n",
    "# SAU KHI IMPUTE: Các giá trị có thể là số thực, cần làm tròn và chuyển về kiểu số nguyên\n",
    "# Sử dụng .loc để tránh SettingWithCopyWarning nếu X_train/X_test là slice\n",
    "for col in ['report_day', 'report_month', 'report_year']:\n",
    "    X_train.loc[:, col] = X_train[col].round().astype('Int64') # Dùng Int64 để giữ NaN nếu có lỗi làm tròn\n",
    "    X_test.loc[:, col] = X_test[col].round().astype('Int64') # Tương tự cho X_test\n",
    "\n",
    "print(\"Đã điền giá trị thiếu cho các cột ngày/tháng/năm bằng KNN imputation.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde86ed8",
   "metadata": {},
   "source": [
    "3. Xóa các cột thừa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4649e387",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop([\"id\",\"prod_code\"],axis=1,inplace=True)\n",
    "X_test.drop([\"id\",\"prod_code\"],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cfa9d84",
   "metadata": {},
   "source": [
    "4. Mã hóa các cột category và chuẩn hóa các cột số"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e464b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_8', 'fea_10',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "categorical_cols = [\n",
    "    'fea_1', 'fea_3', 'fea_5', 'fea_6', 'fea_7', 'fea_9'\n",
    "]\n",
    "\n",
    "# Xác định các cột số có vẻ bị lệch nặng để áp dụng biến đổi Yeo-Johnson\n",
    "skewed_cols = [\n",
    "    'fea_4', 'fea_10',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Các cột số còn lại không áp dụng biến đổi Yeo-Johnson\n",
    "non_skewed_cols = [col for col in numerical_cols if col not in skewed_cols]\n",
    "\n",
    "# Áp dụng biến đổi Yeo-Johnson cho các cột bị lệch trong X_train và X_test\n",
    "yeo_johnson_transformer = PowerTransformer(method='yeo-johnson')\n",
    "\n",
    "# Fit CHỈ trên X_train và transform cả X_train và X_test\n",
    "X_train[skewed_cols] = yeo_johnson_transformer.fit_transform(X_train[skewed_cols])\n",
    "X_test[skewed_cols] = yeo_johnson_transformer.transform(X_test[skewed_cols])\n",
    "\n",
    "# Áp dụng StandardScaler cho TẤT CẢ các cột số trong X_train và X_test\n",
    "scaler = StandardScaler()\n",
    "\n",
    "# Fit CHỈ trên X_train và transform cả X_train và X_test\n",
    "X_train[numerical_cols] = scaler.fit_transform(X_train[numerical_cols])\n",
    "X_test[numerical_cols] = scaler.transform(X_test[numerical_cols])\n",
    "\n",
    "\n",
    "# --- Xử lý cột phân loại (One-Hot Encoding) ---\n",
    "\n",
    "# Khởi tạo OneHotEncoder\n",
    "# handle_unknown='ignore' để xử lý các danh mục mới trong tập test nếu có\n",
    "# sparse_output=False để kết quả là dense array, dễ làm việc với DataFrame\n",
    "ohe = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "\n",
    "# Fit CHỈ trên X_train và transform cả X_train và X_test\n",
    "X_train_cat_encoded = ohe.fit_transform(X_train[categorical_cols])\n",
    "X_test_cat_encoded = ohe.transform(X_test[categorical_cols])\n",
    "\n",
    "# Tạo DataFrame từ kết quả One-Hot Encoding\n",
    "# Lấy tên cột mới sau OHE\n",
    "ohe_feature_names = ohe.get_feature_names_out(categorical_cols)\n",
    "X_train_cat_df = pd.DataFrame(X_train_cat_encoded, index=X_train.index, columns=ohe_feature_names)\n",
    "X_test_cat_df = pd.DataFrame(X_test_cat_encoded, index=X_test.index, columns=ohe_feature_names)\n",
    "\n",
    "# Bỏ các cột phân loại gốc khỏi X_train và X_test\n",
    "X_train = X_train.drop(columns=categorical_cols)\n",
    "X_test = X_test.drop(columns=categorical_cols)\n",
    "\n",
    "# Kết hợp các cột số đã xử lý và các cột phân loại đã mã hóa\n",
    "X_train_processed = pd.concat([X_train, X_train_cat_df], axis=1)\n",
    "X_test_processed = pd.concat([X_test, X_test_cat_df], axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfb79a13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xác định lại danh sách các cột số (tên cột vẫn giữ nguyên sau tiền xử lý số)\n",
    "numerical_cols = [\n",
    "    'fea_2', 'fea_4', 'fea_11', 'fea_8', 'fea_10',\n",
    "    'OVD_t1', 'OVD_t2', 'OVD_sum', 'pay_normal',\n",
    "    'prod_limit', 'new_balance', 'highest_balance'\n",
    "]\n",
    "\n",
    "# Vẽ KDE plot cho các cột số (3 đồ thị trên 1 hàng)\n",
    "print(\"Generating KDE plots for numerical columns in X_train_processed...\")\n",
    "n_numerical = len(numerical_cols)\n",
    "n_rows_numerical = math.ceil(n_numerical / 3)\n",
    "fig_numerical, axes_numerical = plt.subplots(n_rows_numerical, 3, figsize=(18, n_rows_numerical * 5))\n",
    "axes_numerical = axes_numerical.flatten() # Làm phẳng mảng axes 2D thành 1D\n",
    "\n",
    "for i, col in enumerate(numerical_cols):\n",
    "    # Kiểm tra xem cột có tồn tại trong X_train_processed không trước khi vẽ\n",
    "    if col in X_train_processed.columns:\n",
    "        sns.kdeplot(data=X_train_processed, x=col, fill=True, ax=axes_numerical[i])\n",
    "        axes_numerical[i].set_title(f'Phân phối của cột: {col} (Processed)')\n",
    "        axes_numerical[i].set_xlabel(col)\n",
    "        axes_numerical[i].set_ylabel('Mật độ')\n",
    "    else:\n",
    "        # Nếu cột không tồn tại (ví dụ: bị loại bỏ hoặc đổi tên trong quá trình xử lý), ẩn subplot\n",
    "        fig_numerical.delaxes(axes_numerical[i])\n",
    "\n",
    "\n",
    "# Ẩn các subplot không sử dụng nếu số cột không đủ lấp đầy hàng cuối\n",
    "for j in range(i + 1, len(axes_numerical)):\n",
    "    fig_numerical.delaxes(axes_numerical[j])\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"Plot generation complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16e876c3",
   "metadata": {},
   "source": [
    "5. Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e548d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử X_train_processed và X_test_processed là dữ liệu đã qua các bước trên\n",
    "model_baseline = LogisticRegression(random_state=42, solver='liblinear', class_weight='balanced')\n",
    "# class_weight='balanced' nếu dữ liệu mất cân bằng\n",
    "model_baseline.fit(X_train_processed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e95f962",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dự đoán trên tập Train\n",
    "y_pred_train_baseline = model_baseline.predict(X_train_processed)\n",
    "y_pred_proba_train_baseline = model_baseline.predict_proba(X_train_processed)[:, 1] # Xác suất của lớp 1 cho tập train\n",
    "\n",
    "# Dự đoán trên tập Test (bạn đã làm ở bước trước)\n",
    "y_pred_test_baseline = model_baseline.predict(X_test_processed) # Hoặc y_pred_baseline từ bước trước\n",
    "y_pred_proba_test_baseline = model_baseline.predict_proba(X_test_processed)[:, 1] # Hoặc y_pred_proba_baseline từ bước trước"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dc9abae",
   "metadata": {},
   "source": [
    "6. So sánh hiệu suất"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1afec61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Đánh giá trên tập TRAIN ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP HUẤN LUYỆN (TRAIN) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(confusion_matrix(y_train, y_pred_train_baseline))\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_pred_train_baseline))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train_baseline)\n",
    "precision_train = precision_score(y_train, y_pred_train_baseline, zero_division=0) # zero_division=0 để tránh lỗi nếu không có TP+FP\n",
    "recall_train = recall_score(y_train, y_pred_train_baseline, zero_division=0)\n",
    "f1_train = f1_score(y_train, y_pred_train_baseline, zero_division=0)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train_baseline)\n",
    "\n",
    "print(f\"\\nAccuracy (Train): {accuracy_train:.4f}\")\n",
    "print(f\"Precision (Train - cho lớp 1): {precision_train:.4f}\")\n",
    "print(f\"Recall (Train - cho lớp 1): {recall_train:.4f}\")\n",
    "print(f\"F1-score (Train - cho lớp 1): {f1_train:.4f}\")\n",
    "print(f\"ROC AUC (Train): {roc_auc_train:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Đánh giá trên tập TEST ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP KIỂM TRA (TEST) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_baseline))\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_test_baseline))\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test_baseline)\n",
    "precision_test = precision_score(y_test, y_pred_test_baseline, zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test_baseline, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test_baseline, zero_division=0)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test_baseline)\n",
    "\n",
    "print(f\"\\nAccuracy (Test): {accuracy_test:.4f}\")\n",
    "print(f\"Precision (Test - cho lớp 1): {precision_test:.4f}\")\n",
    "print(f\"Recall (Test - cho lớp 1): {recall_test:.4f}\")\n",
    "print(f\"F1-score (Test - cho lớp 1): {f1_test:.4f}\")\n",
    "print(f\"ROC AUC (Test): {roc_auc_test:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# --- So sánh trực tiếp ---\n",
    "print(\"=\"*30 + \" SO SÁNH TRAIN vs TEST \" + \"=\"*30)\n",
    "print(f\"{'Metric':<15} | {'Train':<10} | {'Test':<10} | {'Difference (Train-Test)':<25}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Accuracy':<15} | {accuracy_train:<10.4f} | {accuracy_test:<10.4f} | {accuracy_train - accuracy_test:<25.4f}\")\n",
    "print(f\"{'Precision (1)':<15} | {precision_train:<10.4f} | {precision_test:<10.4f} | {precision_train - precision_test:<25.4f}\")\n",
    "print(f\"{'Recall (1)':<15} | {recall_train:<10.4f} | {recall_test:<10.4f} | {recall_train - recall_test:<25.4f}\")\n",
    "print(f\"{'F1-score (1)':<15} | {f1_train:<10.4f} | {f1_test:<10.4f} | {f1_train - f1_test:<25.4f}\")\n",
    "print(f\"{'ROC AUC':<15} | {roc_auc_train:<10.4f} | {roc_auc_test:<10.4f} | {roc_auc_train - roc_auc_test:<25.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d112a43f",
   "metadata": {},
   "source": [
    "#### Đánh giá Mô hình Baseline và Đề xuất Các Bước Tiếp Theo\n",
    "\n",
    "**Kết luận về Mô hình Baseline:**\n",
    "\n",
    "*   Mô hình baseline hiện tại là một **điểm khởi đầu tốt**.\n",
    "*   **Không có dấu hiệu overfitting rõ ràng:** Hiệu suất trên tập huấn luyện và tập kiểm tra khá tương đồng.\n",
    "*   Mô hình có **khả năng phân loại nhất định** (ví dụ, ROC AUC ~0.73 - 0.75, cao hơn mức ngẫu nhiên 0.5).\n",
    "*   **Thách thức chính:**\n",
    "    *   **Precision cho lớp 1 (Rủi ro) còn rất thấp** (khoảng 0.29), dẫn đến nhiều dự đoán sai dương (False Positives).\n",
    "    *   **F1-score cho lớp 1 cũng thấp** (khoảng 0.40) do ảnh hưởng của Precision thấp.\n",
    "    *   Recall cho lớp 1 ở mức khá (khoảng 0.67 - 0.69), cho thấy mô hình bắt được một phần đáng kể các trường hợp rủi ro.\n",
    "*   Vấn đề **mất cân bằng dữ liệu** (lớp 0 chiếm đa số) có thể là một trong những nguyên nhân chính ảnh hưởng đến Precision của lớp 1.\n",
    "\n",
    "**Đề xuất cho các bước tiếp theo:**\n",
    "\n",
    "Mục tiêu chính là cải thiện khả năng dự đoán cho lớp 1 (Rủi ro), đặc biệt là cân bằng giữa Precision và Recall tùy theo yêu cầu nghiệp vụ.\n",
    "\n",
    "1.  **Xử lý Mất cân bằng Dữ liệu (Imbalanced Data) một cách Triệt để hơn:**\n",
    "    *   **Phương pháp:**\n",
    "        *   **Oversampling lớp thiểu số:** SMOTE, ADASYN.\n",
    "        *   **Undersampling lớp đa số:** RandomUnderSampler, NearMiss, Tomek Links.\n",
    "        *   **Kết hợp Oversampling và Undersampling:** Ví dụ, SMOTEENN, SMOTETomek.\n",
    "    *   **Lưu ý quan trọng:** Các kỹ thuật này phải được áp dụng **CHỈ trên tập huấn luyện (`X_train`)** sau khi đã chia train/test để tránh data leakage.\n",
    "\n",
    "2.  **Feature Engineering Sâu hơn:**\n",
    "    *   **Tạo Feature Tương tác (Interaction Features):** Kết hợp các biến hiện có để tạo ra các feature mới có thể nắm bắt mối quan hệ phức tạp hơn (ví dụ: `fea_2 * prod_limit`, hoặc các tương tác dựa trên kiến thức nghiệp vụ).\n",
    "    *   **Khai thác Biến Thời gian:**\n",
    "        *   Tạo các feature về xu hướng (ví dụ: thay đổi số dư trong 3 tháng cuối, độ dốc của `OVD_sum` theo thời gian).\n",
    "        *   Tạo các feature về tần suất (ví dụ: số lần cập nhật/thanh toán trong một khoảng thời gian).\n",
    "        *   Tính toán các độ trễ, khoảng thời gian giữa các sự kiện quan trọng.\n",
    "    *   **Xử lý Biến Categorical có nhiều giá trị:**\n",
    "        *   **Target Encoding (Mean Encoding):** Thay thế category bằng giá trị trung bình của biến mục tiêu cho category đó (cẩn thận với overfitting, cần sử dụng trên tập train và áp dụng cho test, hoặc dùng cross-validation).\n",
    "        *   **Frequency Encoding:** Thay thế category bằng tần suất xuất hiện của nó.\n",
    "        *   **Gộp nhóm các category hiếm** thành một nhóm \"Other\".\n",
    "    *   **Giải quyết Vấn đề Chất lượng Dữ liệu:**\n",
    "        *   Nghiên cứu và đưa ra chiến lược xử lý cho các trường hợp có cùng `update_date` nhưng thông tin khác nhau cho cùng một (`id`, `prod_code`).\n",
    "\n",
    "3.  **Lựa chọn Feature (Feature Selection):**\n",
    "    *   Sau khi có nhiều feature hơn, sử dụng các kỹ thuật lựa chọn feature (ví dụ: dựa trên feature importance của mô hình, Recursive Feature Elimination - RFE, SelectKBest) để loại bỏ các feature nhiễu hoặc ít đóng góp, giúp mô hình tập trung vào các tín hiệu quan trọng.\n",
    "\n",
    "4.  **Thử nghiệm các Mô hình Mạnh mẽ hơn:**\n",
    "    *   **Random Forest:** Thường cho kết quả tốt và ít bị overfitting hơn Decision Tree đơn lẻ.\n",
    "    *   **Gradient Boosting Machines (GBMs):**\n",
    "        *   **XGBoost**\n",
    "        *   **LightGBM** (thường nhanh hơn XGBoost và hiệu quả trên tập dữ liệu lớn)\n",
    "        *   **CatBoost** (xử lý tốt biến categorical tự động)\n",
    "    *   Các mô hình này có khả năng học các mối quan hệ phi tuyến và tương tác giữa các feature một cách hiệu quả.\n",
    "\n",
    "5.  **Tinh chỉnh Ngưỡng Quyết định (Decision Threshold):**\n",
    "    *   Đối với các mô hình phân loại nhị phân, thay vì sử dụng ngưỡng mặc định 0.5 trên `predict_proba`, hãy thử nghiệm các ngưỡng khác nhau.\n",
    "    *   Sử dụng đường cong **Precision-Recall Curve** để tìm ngưỡng tối ưu hóa F1-score, hoặc một điểm cân bằng giữa Precision và Recall phù hợp với yêu cầu nghiệp vụ.\n",
    "\n",
    "6.  **Tinh chỉnh Siêu tham số (Hyperparameter Tuning):**\n",
    "    *   Sau khi đã chọn được một hoặc vài mô hình tiềm năng và có bộ feature tốt, sử dụng các kỹ thuật như GridSearchCV, RandomizedSearchCV, hoặc các thư viện tối ưu hóa siêu tham số (ví dụ: Optuna, Hyperopt) để tìm bộ siêu tham số tốt nhất cho mô hình.\n",
    "\n",
    "Bằng cách thực hiện các bước này một cách có hệ thống, bạn có khả năng cao sẽ cải thiện đáng kể hiệu suất của mô hình so với baseline hiện tại."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93cebe18",
   "metadata": {},
   "source": [
    "## Triển khai mô hình thứ 2: RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa6ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Khởi tạo mô hình Random Forest (có thể dùng cùng tham số như Cách 1 để so sánh công bằng)\n",
    "rf_model_v2 = RandomForestClassifier(random_state=42, \n",
    "                                     n_estimators=100, \n",
    "                                     class_weight='balanced_subsample' if y_train.value_counts(normalize=True)[1] < 0.4 else None)\n",
    "\n",
    "# Huấn luyện mô hình\n",
    "rf_model_v2.fit(X_train_processed, y_train) # Sử dụng X_train_c2 đã qua xử lý kỹ lưỡng\n",
    "\n",
    "# Dự đoán trên tập Train và Test\n",
    "y_pred_train_v2 = rf_model_v2.predict(X_train_processed)\n",
    "y_pred_proba_train_v2 = rf_model_v2.predict_proba(X_train_processed)[:, 1]\n",
    "\n",
    "y_pred_test_v2 = rf_model_v2.predict(X_test_processed)\n",
    "y_pred_proba_test_v2 = rf_model_v2.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70f680c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Đánh giá trên tập TRAIN ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP HUẤN LUYỆN (TRAIN) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(confusion_matrix(y_train, y_pred_train_v2))\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_pred_train_v2))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train_v2)\n",
    "precision_train = precision_score(y_train, y_pred_train_v2, zero_division=0) # zero_division=0 để tránh lỗi nếu không có TP+FP\n",
    "recall_train = recall_score(y_train, y_pred_train_v2, zero_division=0)\n",
    "f1_train = f1_score(y_train, y_pred_train_v2, zero_division=0)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train_v2)\n",
    "\n",
    "print(f\"\\nAccuracy (Train): {accuracy_train:.4f}\")\n",
    "print(f\"Precision (Train - cho lớp 1): {precision_train:.4f}\")\n",
    "print(f\"Recall (Train - cho lớp 1): {recall_train:.4f}\")\n",
    "print(f\"F1-score (Train - cho lớp 1): {f1_train:.4f}\")\n",
    "print(f\"ROC AUC (Train): {roc_auc_train:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Đánh giá trên tập TEST ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP KIỂM TRA (TEST) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_v2))\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_test_v2))\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test_v2)\n",
    "precision_test = precision_score(y_test, y_pred_test_v2, zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test_v2, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test_v2, zero_division=0)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test_v2)\n",
    "\n",
    "print(f\"\\nAccuracy (Test): {accuracy_test:.4f}\")\n",
    "print(f\"Precision (Test - cho lớp 1): {precision_test:.4f}\")\n",
    "print(f\"Recall (Test - cho lớp 1): {recall_test:.4f}\")\n",
    "print(f\"F1-score (Test - cho lớp 1): {f1_test:.4f}\")\n",
    "print(f\"ROC AUC (Test): {roc_auc_test:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# --- So sánh trực tiếp ---\n",
    "print(\"=\"*30 + \" SO SÁNH TRAIN vs TEST \" + \"=\"*30)\n",
    "print(f\"{'Metric':<15} | {'Train':<10} | {'Test':<10} | {'Difference (Train-Test)':<25}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Accuracy':<15} | {accuracy_train:<10.4f} | {accuracy_test:<10.4f} | {accuracy_train - accuracy_test:<25.4f}\")\n",
    "print(f\"{'Precision (1)':<15} | {precision_train:<10.4f} | {precision_test:<10.4f} | {precision_train - precision_test:<25.4f}\")\n",
    "print(f\"{'Recall (1)':<15} | {recall_train:<10.4f} | {recall_test:<10.4f} | {recall_train - recall_test:<25.4f}\")\n",
    "print(f\"{'F1-score (1)':<15} | {f1_train:<10.4f} | {f1_test:<10.4f} | {f1_train - f1_test:<25.4f}\")\n",
    "print(f\"{'ROC AUC':<15} | {roc_auc_train:<10.4f} | {roc_auc_test:<10.4f} | {roc_auc_train - roc_auc_test:<25.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b24e23f2",
   "metadata": {},
   "source": [
    "-> Mặc dù con số trên tập test là khá ấn tượng, xong ta thấy hiện tượng overfitting nặng"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea12b144",
   "metadata": {},
   "source": [
    "#### Phương án xử lý: tìm bộ siêu tham số giúp cân bằng giữa train và test bằng cách áp dụng RandomizedSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62c16770",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import randint\n",
    "# Định nghĩa không gian siêu tham số để tìm kiếm\n",
    "param_distributions = {\n",
    "    'n_estimators': randint(100, 500),  # Số cây từ 100 đến 499\n",
    "    'max_depth': [5, 8, 10, 15, 20, 25, 30, None], # Vẫn có thể dùng danh sách cho một số tham số\n",
    "    'min_samples_split': randint(2, 21), # Số mẫu tối thiểu để chia từ 2 đến 20\n",
    "    'min_samples_leaf': randint(1, 21),  # Số mẫu tối thiểu ở lá từ 1 đến 20\n",
    "    'max_features': ['sqrt', 'log2', 0.3, 0.5, 0.7], # Có thể dùng danh sách hoặc phân phối\n",
    "    'class_weight': [None, 'balanced', 'balanced_subsample'],\n",
    "    'bootstrap': [True, False] # Thêm một tham số ví dụ\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42,oob_score=True)\n",
    "\n",
    "# Sử dụng GridSearchCV\n",
    "random_search = RandomizedSearchCV(estimator=rf_clf,\n",
    "                                   param_distributions=param_distributions,\n",
    "                                   n_iter=50,  # Thử 50 tổ hợp ngẫu nhiên (bạn có thể điều chỉnh)\n",
    "                                   cv=3,\n",
    "                                   verbose=2,\n",
    "                                   random_state=42,\n",
    "                                   n_jobs=-1,\n",
    "                                   scoring='roc_auc') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f6496ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit RandomizedSearchCV trên dữ liệu huấn luyện\n",
    "print(\"Bắt đầu RandomizedSearchCV...\")\n",
    "random_search.fit(X_train_processed, y_train)\n",
    "print(\"RandomizedSearchCV hoàn thành.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992ef631",
   "metadata": {},
   "outputs": [],
   "source": [
    "# In ra các siêu tham số tốt nhất\n",
    "print(\"\\nSiêu tham số tốt nhất tìm được từ RandomizedSearchCV:\")\n",
    "print(random_search.best_params_)\n",
    "\n",
    "# Lấy mô hình tốt nhất\n",
    "best_rf_model_random = random_search.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f84202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Đánh giá mô hình tốt nhất trên tập train và test\n",
    "y_pred_train_best_random = best_rf_model_random.predict(X_train_processed)\n",
    "y_pred_proba_train_best_random = best_rf_model_random.predict_proba(X_train_processed)[:, 1]\n",
    "\n",
    "y_pred_test_best_random = best_rf_model_random.predict(X_test_processed)\n",
    "y_pred_proba_test_best_random = best_rf_model_random.predict_proba(X_test_processed)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761fbee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- Đánh giá trên tập TRAIN ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP HUẤN LUYỆN (TRAIN) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Train):\")\n",
    "print(confusion_matrix(y_train, y_pred_train_best_random))\n",
    "print(\"\\nClassification Report (Train):\")\n",
    "print(classification_report(y_train, y_pred_train_best_random))\n",
    "\n",
    "accuracy_train = accuracy_score(y_train, y_pred_train_best_random)\n",
    "precision_train = precision_score(y_train, y_pred_train_best_random, zero_division=0) # zero_division=0 để tránh lỗi nếu không có TP+FP\n",
    "recall_train = recall_score(y_train, y_pred_train_best_random, zero_division=0)\n",
    "f1_train = f1_score(y_train, y_pred_train_best_random, zero_division=0)\n",
    "roc_auc_train = roc_auc_score(y_train, y_pred_proba_train_best_random)\n",
    "\n",
    "print(f\"\\nAccuracy (Train): {accuracy_train:.4f}\")\n",
    "print(f\"Precision (Train - cho lớp 1): {precision_train:.4f}\")\n",
    "print(f\"Recall (Train - cho lớp 1): {recall_train:.4f}\")\n",
    "print(f\"F1-score (Train - cho lớp 1): {f1_train:.4f}\")\n",
    "print(f\"ROC AUC (Train): {roc_auc_train:.4f}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "\n",
    "# --- Đánh giá trên tập TEST ---\n",
    "print(\"=\"*30 + \" KẾT QUẢ TRÊN TẬP KIỂM TRA (TEST) \" + \"=\"*30)\n",
    "print(\"Confusion Matrix (Test):\")\n",
    "print(confusion_matrix(y_test, y_pred_test_best_random))\n",
    "print(\"\\nClassification Report (Test):\")\n",
    "print(classification_report(y_test, y_pred_test_best_random))\n",
    "\n",
    "accuracy_test = accuracy_score(y_test, y_pred_test_best_random)\n",
    "precision_test = precision_score(y_test, y_pred_test_best_random, zero_division=0)\n",
    "recall_test = recall_score(y_test, y_pred_test_best_random, zero_division=0)\n",
    "f1_test = f1_score(y_test, y_pred_test_best_random, zero_division=0)\n",
    "roc_auc_test = roc_auc_score(y_test, y_pred_proba_test_best_random)\n",
    "\n",
    "print(f\"\\nAccuracy (Test): {accuracy_test:.4f}\")\n",
    "print(f\"Precision (Test - cho lớp 1): {precision_test:.4f}\")\n",
    "print(f\"Recall (Test - cho lớp 1): {recall_test:.4f}\")\n",
    "print(f\"F1-score (Test - cho lớp 1): {f1_test:.4f}\")\n",
    "print(f\"ROC AUC (Test): {roc_auc_test:.4f}\")\n",
    "print(f\"OOB score: {best_rf_model_random.o}\")\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "\n",
    "# --- So sánh trực tiếp ---\n",
    "print(\"=\"*30 + \" SO SÁNH TRAIN vs TEST \" + \"=\"*30)\n",
    "print(f\"{'Metric':<15} | {'Train':<10} | {'Test':<10} | {'Difference (Train-Test)':<25}\")\n",
    "print(\"-\"*70)\n",
    "print(f\"{'Accuracy':<15} | {accuracy_train:<10.4f} | {accuracy_test:<10.4f} | {accuracy_train - accuracy_test:<25.4f}\")\n",
    "print(f\"{'Precision (1)':<15} | {precision_train:<10.4f} | {precision_test:<10.4f} | {precision_train - precision_test:<25.4f}\")\n",
    "print(f\"{'Recall (1)':<15} | {recall_train:<10.4f} | {recall_test:<10.4f} | {recall_train - recall_test:<25.4f}\")\n",
    "print(f\"{'F1-score (1)':<15} | {f1_train:<10.4f} | {f1_test:<10.4f} | {f1_train - f1_test:<25.4f}\")\n",
    "print(f\"{'ROC AUC':<15} | {roc_auc_train:<10.4f} | {roc_auc_test:<10.4f} | {roc_auc_train - roc_auc_test:<25.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e7beda8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "try:\n",
    "    feature_names = X_train_processed.columns\n",
    "except AttributeError:\n",
    "    # Nếu X_train_processed là numpy array, bạn cần có danh sách tên feature từ trước\n",
    "    # Ví dụ: feature_names = list_of_your_feature_names_in_order\n",
    "    print(\"X_train_processed không phải là DataFrame. Hãy đảm bảo bạn có danh sách feature_names chính xác.\")\n",
    "    # Dừng lại hoặc cung cấp feature_names thủ công\n",
    "    # feature_names = [...] # Điền tên feature của bạn vào đây theo đúng thứ tự\n",
    "\n",
    "# Lấy giá trị feature importances từ mô hình\n",
    "importances = best_rf_model_random.feature_importances_\n",
    "\n",
    "# Tạo một Series Pandas để dễ dàng xem và sắp xếp\n",
    "forest_importances = pd.Series(importances, index=feature_names)\n",
    "\n",
    "# Sắp xếp các feature theo tầm quan trọng giảm dần\n",
    "sorted_forest_importances = forest_importances.sort_values(ascending=False)\n",
    "\n",
    "# In ra các feature quan trọng nhất (ví dụ: top 20)\n",
    "print(\"Top 20 Feature Importances từ Random Forest:\")\n",
    "print(sorted_forest_importances.head(20))\n",
    "\n",
    "# Trực quan hóa Feature Importances (ví dụ: top 20)\n",
    "plt.figure(figsize=(10, 8)) # Điều chỉnh kích thước nếu cần\n",
    "top_n = 20\n",
    "sns.barplot(x=sorted_forest_importances.head(top_n).values, y=sorted_forest_importances.head(top_n).index)\n",
    "# Hoặc dùng pandas plot:\n",
    "# sorted_forest_importances.head(top_n).plot(kind='barh')\n",
    "plt.title(f'Top {top_n} Feature Importances từ Random Forest')\n",
    "plt.xlabel('Importance')\n",
    "plt.ylabel('Feature')\n",
    "plt.gca().invert_yaxis() # Để feature quan trọng nhất ở trên cùng nếu dùng barh\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2501266e",
   "metadata": {},
   "source": [
    "-> Không có feature nào vượt trội, khá tương đồng nhau. Cho thấy mô hình đang học từ nhiều khía cạnh của dữ liệu"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
