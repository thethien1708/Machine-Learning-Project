{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Breast Cancer Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import time\n",
    "from scipy import stats\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NOTE:  \n",
    "Thuật toán K-Nearest Neighbors là một thuật toán phân loại mạnh mẽ nhưng đơn giản. Nó đưa ra dự đoán bằng cách so sánh các điểm dữ liệu mới với k điểm dữ liệu gần nhất và gán lớp dựa trên lớp chiếm đa số của các điểm láng giềng đó.\n",
    "\n",
    "Lưu ý rằng không có giai đoạn huấn luyện như trong các thuật toán học máy khác. Thay vào đó, tập dữ liệu huấn luyện chỉ được lưu lại để sử dụng trong giai đoạn dự đoán sau này."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Một vài vấn đề khi chọn K:  \n",
    "Hiệu suất của thuật toán có thể nhạy cảm với giá trị của k. Khi k nhỏ, mô hình nhạy cảm với nhiễu và dễ bị overfitting, trong khi các giá trị k lớn có thể dẫn đến underfitting, đặc biệt nếu có sự mất cân bằng giữa các lớp.\n",
    "\n",
    "Khi số lượng lớp là 2, k nên là một số lẻ để tránh tình trạng \"bỏ phiếu hòa\" khi đưa ra dự đoán.\n",
    "\n",
    "Giá trị của k nên lớn hơn số lượng lớp vì những lý do tương tự."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tập dữ liệu:\n",
    "Tập dữ liệu chúng ta làm việc lần này là UCI breast cancer dataset (có sẵn link trên kaggle). Bài toán ta cần giải quyết là classification để dự đoán 1 người có mắc ung thư vú hay không"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "data = pd.read_csv('data.csv',index_col='id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Basic EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.drop(['Unnamed: 32'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.heatmap(data.corr(numeric_only=True))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Giả sử bạn có DataFrame df và muốn vẽ phân phối cho các cột số\n",
    "numeric_columns = data.select_dtypes(include='number').columns  # Chọn các cột số trong DataFrame\n",
    "\n",
    "# Số lượng cột số\n",
    "n = len(numeric_columns)\n",
    "\n",
    "# Thiết lập số dòng và cột cho lưới vẽ\n",
    "fig, axes = plt.subplots(nrows=(n // 3) + (n % 3), ncols=3, figsize=(15, 5 * ((n // 3) + (n % 3))))\n",
    "\n",
    "# Làm phẳng các axes\n",
    "axes = axes.flatten()\n",
    "\n",
    "# Vẽ phân phối cho mỗi cột số\n",
    "for i, col in enumerate(numeric_columns):\n",
    "    axes[i].hist(data[col], bins=30, alpha=0.7)\n",
    "    axes[i].set_title(f'Phân phối của {col}')\n",
    "    axes[i].set_xlabel(col)\n",
    "    axes[i].set_ylabel('Tần suất')\n",
    "\n",
    "# Ẩn đi các axes thừa\n",
    "for j in range(i + 1, len(axes)):\n",
    "    axes[j].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.pie(data[\"diagnosis\"].value_counts(), labels=[\"Benign\", \"Malignant\"], autopct='%1.1f%%')\n",
    "plt.title(\"Tỷ lệ phân loại của biến mục tiêu\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pre-processing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop('diagnosis', axis=1)\n",
    "y = data['diagnosis']\n",
    "\n",
    "# Encode label\n",
    "y = y.map({'M': 1, 'B': 0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do tập dữ liệu đã được làm sạch từ trước đó nên công việc làm sạch ta bỏ qua"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Split data 80/20\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Xây dựng model KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class kNN():\n",
    "    '''k-Nearest Neighbours'''\n",
    "    # Initialise\n",
    "    def __init__(self, k=3, metric='euclidean', p=None):\n",
    "        self.k = k\n",
    "        self.metric = metric\n",
    "        self.p = p\n",
    "    \n",
    "    # Euclidean distance (l2 norm)\n",
    "    def euclidean(self, v1, v2):\n",
    "        return np.sqrt(np.sum((v1-v2)**2))\n",
    "    \n",
    "    # Manhattan distance (l1 norm)\n",
    "    def manhattan(self, v1, v2):\n",
    "        return np.sum(np.abs(v1-v2))\n",
    "    \n",
    "    # Minkowski distance (lp norm)\n",
    "    def minkowski(self, v1, v2, p=2):\n",
    "        return np.sum(np.abs(v1-v2)**p)**(1/p)\n",
    "        \n",
    "    # Store train set\n",
    "    def fit(self, X_train, y_train):\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        \n",
    "    # Make predictions\n",
    "    def predict(self, X_test):\n",
    "        preds = []\n",
    "        # Loop over rows in test set\n",
    "        for test_row in X_test:\n",
    "            nearest_neighbours = self.get_neighbours(test_row)\n",
    "            majority = stats.mode(nearest_neighbours)[0][0]\n",
    "            preds.append(majority)\n",
    "        return np.array(preds)\n",
    "    \n",
    "    # Get nearest neighbours\n",
    "    def get_neighbours(self, test_row):\n",
    "        distances = list()\n",
    "        \n",
    "        # Calculate distance to all points in X_train\n",
    "        for (train_row, train_class) in zip(self.X_train, self.y_train):\n",
    "            if self.metric=='euclidean':\n",
    "                dist = self.euclidean(train_row, test_row)\n",
    "            elif self.metric=='manhattan':\n",
    "                dist = self.manhattan(train_row, test_row)\n",
    "            elif self.metric=='minkowski':\n",
    "                dist = self.minkowski(train_row, test_row, self.p)\n",
    "            else:\n",
    "                raise NameError('Supported metrics are euclidean, manhattan and minkowski')\n",
    "            distances.append((dist, train_class))\n",
    "            \n",
    "        # Sort distances\n",
    "        distances.sort(key=lambda x: x[0])\n",
    "        \n",
    "        # Identify k nearest neighbours\n",
    "        neighbours = list()\n",
    "        for i in range(self.k):\n",
    "            neighbours.append(distances[i][1])\n",
    "            \n",
    "        return neighbours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, y_test):\n",
    "    return 100 * (preds == y_test).mean()\n",
    "\n",
    "clf = kNN(k=5,metric='euclidean')\n",
    "clf.fit(X_train.values,y_train.values)\n",
    "preds = clf.predict(X_test.values)\n",
    "\n",
    "print(f\"Accuracy: {accuracy(preds, y_test)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
